%\VignetteIndexEntry{getting-started}
\documentclass[a4paper, 11pt, fleqn]{article}
\usepackage[english]{babel}
\usepackage{amsmath,amssymb}
\usepackage{natbib}
\newcommand{\bs}[1]{\boldsymbol{#1}}

%\usepackage[default]{comfortaa}
\usepackage[T1]{fontenc}
\usepackage{palatino}

\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\R}{\code{R}}
\usepackage{inconsolata}

\DeclareMathOperator*{\argmin}{\arg\min}

\setlength{\parindent}{0pt}
\setlength{\parskip}{1ex}

% tussenvoegsel hack.
\DeclareRobustCommand{\VAN}[3]{#2}


\title{The \code{rspa} package\\
  {\small Package version \Sexpr{packageVersion("rspa")}}
}
\author{Mark van der Loo}
\date{\today}




\begin{document}
\SweaveOpts{concordance=TRUE}
<<setup, include=FALSE, cache=FALSE>>=
library(knitr)
opts_chunk$set(
    size='small'
#    prompt=TRUE,
#    comment=''
)
@


<<include=FALSE >>=
library(rspa)
library(editrules)
@
\maketitle

\begin{abstract}
The \code{R} extension package \code{rspa} offers functionality to minimally
adjust a vector $\bs{x}$ such that it obeys the system of (in)equations
$\bs{Ax}\leq \bs{b}$. The package implements the successive projection
algorithm that was recently described by \cite{pannekoek:2012}. There are are several ways to define what
``minimal'' means here, and the package works for fairly large systems of
equations.  Thus far it has been tested on systems with on the order of
$10^5-10^6$ variables and $10^4-10^5$ restrictions. Convergence is usually
reached within seconds.
\end{abstract}

\tableofcontents

\newpage

\section{Introduction}
In statistics one is often confronted with records or sets of estimated values
that have to obey a set of linear equations and/or inequations. Examples
include records from business surveys that have to obey accountancy rules or
production-consumption balances for national account systems.  In practice,
such data seldom obeys all restrictions leading to further inconsistencies
when the data is used as input for further analyses. One solution is to
minimally adjust the data so that all restrictions are obeyed. 

Here, with minimal adjustment we mean that a record $\bs{x}^0\in\mathbb{R}^n$ is replaced
with a value $\bs{x}$ such that the objective function
\begin{equation}
d(\bs{x},\bs{x}^0) = \left[(\bs{x} - \bs{x}^0)'\bs{W}(\bs{x}-\bs{x}^0)\right]^{1/2},
\end{equation}
is minimized as a function of $\bs{x}$, subject to 
\begin{equation}
\bs{Ax} \leq \bs{b}.
\label{eq:restrictions}
\end{equation}
Here, $\bs{W}$ is a diagonal positive weight matrix. 

Note that this problem has a simple geometric interpretation. The system $\bs{Ax}\leq \bs{b}$
describes a convex region of $\mathbb{R}^n$ (possibly of lower dimension than $n$). The problem
is to replace the vector $\bs{x}^0$ outside this region with a record $\bs{x}$ lying in it while
keeping the distance $d(\bs{x},\bs{x}^0)$ as small as possible.

The algorithm implemented in the \code{rspa} package was first published by
\cite{hildreth:1957} and was recently rediscovered by \cite{pannekoek:2012},
who named it the {\em successive projection algorithm}. It minimizes
$d(\bs{x},\bs{x}^0)$ as a function of $\bs{x}$ so that the restrictions are
obeyed up to a certain {\em accuracy}.  This accuracy is defined as the maximum
absolute deviance from Eq.\ \eqref{eq:restrictions} and will be defined more
precisely in Section \ref{sect:algorithm}.


The rest of this paper is structured
as follows. In Sections \ref{sect:simpleexample} to \ref{sect:largeproblems} we
demonstrate some of the package's core functionality. Sections \ref{sect:algorithm}
and \ref{sect:implementation} provide some details on the inner workings of the
package which may help users to interpret the results. 


\section{A simple example}
\label{sect:simpleexample}
The following example is borrowed from \cite{pannekoek:2012} and involves
profit-loss account balances from a business survey. The problem described in
the reference involves a record of eight variables $x_1\ldots x_8$ that have
to obey the following rules.
%
\begin{eqnarray*}
x_5 &=& x_1 + x_8\\
x_5 &=& x_3 + x_4\\
x_8 &=& x_6 + x_7\\
x_4 &\geq& 0.
\end{eqnarray*}
%
The first task is to define these constraints in \R{}. The \code{rspa} package
offers several ways to do this.  One option, which we will use in this problem
is to make use of the \code{editrules} package \citep{jonge:2011}.
%
<<tidy=FALSE>>=
E <- editmatrix(expression(
    x5 == x1 + x8,
    x5 == x3 + x4,
    x8 == x6 + x7,
    x4 > 0))
@
%
%
The record in the example has the following values
<<tidy=FALSE>>=
x <- c(
   x1=330,
   x2=20,
   x3=1000,
   x4=30,
   x5=950,
   x6=500,
   x7=200,
   x8=700)
@ 
%
To confirm that this vector does not meet the constraints, we call \code{violatedEdits} (also part of \code{editrules}).
<<>>=
violatedEdits(E,x,tol=1e-2)
@
This shows that $x$ violates the first two rules (indicated with \code{TRUE}), at least to within
a tolerance of $0.01$.

In the example of \cite{pannekoek:2012}, the value of $x_5$ is considered
correct. We can therefore substitute it in the set of constraints
(\code{substValue}) and remove the corresponding variable from the set of
constraints (\code{reduce}).
\label{code:substvalue}
<<>>=
E <- reduce(substValue(E,'x5',x['x5']))
@
%
Adjusting $\bs{x}$ with the \code{adjust} function from \code{rspa} so 
it meets the constraints can be done as follows.
<<>>=
(y <- adjust(E, x))
@
%
The result is an object of class \code{adjusted}, which holds the found
solution and some convergence information on the algorithm. The solution can be
accessed as \code{y\$x}.  Using \code{violatedEdits} again, we see that now all
restrictions are obeyed.
<<>>=
violatedEdits(E, y$x, tol = 1e-2)
@
The output shows that the solution obeys the restrictions to within $10^{-2}$.
We will focus on the convergence criterion in the next section but before that,
note the following properties of the \code{adjust} function.
\begin{itemize}
\item It only adjusts variables in $\bs{x}$ that occur in at least one of the restrictions.
\item If the first argument
of \code{adjust} is an \code{editmatrix} and the variables in $\bs{x}$ are
named, they will automatically be matched so the order of variables is unimportant.
\end{itemize} 
The \code{adjust} function is a generic function and it accepts constraints in
\code{matrix}, \code{sparseConstraints} or \code{editmatrix} format. For small
adjustment problems, up to say a few hundred variables and constraints, the
\code{matrix} or \code{editmatrix} format will be fine. Large problems, with
thousands of variables and restrictions can be defined in sparse format and
the adjustment problem is solved with a routine for sparse adjustment.


\section{Treating many records}
\label{sect:manyrecords}
To facilitate production-wise processing of many records, the function
\code{adjustRecords} can adjust all records in a \code{data.frame} to meet
the same set of rules. The output contains the adjusted records as well
as logging information.

As an example, we create a new set of rules and generate some random data.
<<>>=
F <- editmatrix(expression(
	x + y == z,
   x >= 0,
	y >= 0,
	z >=0
))
N <- 100
dat <- data.frame(
	x = runif(100),
	y = rnorm(100),
	z = rlnorm(100)
)
@
By construction, it is very unlikely that all generated data obey the rules in
\code{F}.  To adjust the data, a single call to \code{adjustRecords} is
sufficient.
<<>>=
A <- adjustRecords(F,dat)
summary(A)
@
By default, all variables in \code{dat} are adjusted to meet the rules in
\code{F}.  However, one can optionally pass an array indicating which variables
to adjust.  It is also possible to pass (an \code{array} or \code{vector} of)
weights to control the relative amount of change per variable. The return value
of \code{adjustRecords} is an object of class \code{adjustedValues}. It
contains the adjusted records in \code{A\$adjusted} and a \code{data.frame}
collecting status information in \code{A\$status}.
\begin{figure}
<<>>=
plot(A)
@
\caption{Plotting an object of class \code{adjustedRecords} yields a density plot of the
accuracy (deviance from constraints) and objective function value per record.}
\label{fig:adjustedRecords}
\end{figure}


The \code{R} generic \code{summary} and \code{plot} functions have been overloaded
to get a quick glance of result quality and amount of change from the original data.
Figure \ref{fig:adjustedRecords} shows the result of plotting \code{A} of the
above example. Two plots are created. The top panel shows a kernel density estimate of 
the accuracy values for each record. The lower panel shows a kernel density estimate
of the objective function value. The actual values are shown as a ``rug plot'' under
the density plots. 

It is well-known that kernel density estimates can extrapolate into regions
where the actual probability density equals zero. Here, we need to make sure
that the estimated probability density for accuracy or objective function
equals zero for values $<0$. This is achieved by estimating the accuracy
density under a square root transform, and transforming back for graphical
representation. For the objective function a $\log$-transform is applied.




\section{Treating large problems}
\label{sect:largeproblems}
For problems where $\bs{x}$ has many coefficients and when there are many restrictions,
the package includes an adjustment algorithm based on a sparse representation of the
restrictions. In a sparse representation, elements of the restriction matrix $\bs{A}$
that are zero are not stored in computer memory.

Such a sparse representation is held in a \code{sparseConstraints} object. 
The function \code{sparseConstraints} constructs such objects and accepts arguments in the
form of either
\begin{itemize}
\item An \code{editmatrix}
\item A \code{matrix} $\bs{A}$, a constant vector $\bs{b}$ and an integer $n_=$ indicating which
rows of $\bs{A}$ represent equalities.
\item A \code{data.frame} holding row indices, column indices and coefficients of $\bs{A}$ in 
its three columns, the vector $\bs{b}$ and $n_=$.
\end{itemize}
%
For large problems, the \code{data.frame} method is probably the most convenient so this will
be demonstrated below.

Consider again the constraints in \code{E} of page \pageref{code:substvalue}. After substituting
$x_5=950$, it reads:
<<>>=
E
@
%
To create an object of class \code{sparseConstraints} we generate a
\code{data.frame} called \code{rc} and a vector \code{b}:
<<echo=TRUE,tidy=FALSE>>=
rc <- data.frame(
   row = c( 1, 1, 2, 2, 3, 3, 3, 4),
   col = c( 1, 2, 3, 4, 2, 5, 6, 4),
  coef = c(-1,-1,-1,-1, 1,-1,-1,-1)
)
b <- c(-950, -950, 0,0)
@
Compare these indices and coefficients with the \code{editmatrix} representation above.
With the \code{sparseConstraints} function a sparse representation is generated.
<<>>=
e <- sparseConstraints(rc, b, neq=3, sorted=TRUE)
e
@
By passing the argument \code{sorted=TRUE}, we tell \code{sparseConstraints}
that the input \code{data.frame} is sorted increasingly by column number (so it
does not have to sort it again). The function detected here that row- and
column indices are ``base 1'' (the lowest value equals 1). It is also possible
to pass coefficient definitions which are base 0. Note that we did not feed
\code{sparseConstraints} any names, so it makes up some names to represent the
rules in textual form. 

The \code{sparseConstraints} object is a \emph{reference object} that holds
a pointer to an object outside of \code{R}'s memory. Therefore, objects of
class \code{sparseConstraints}
\begin{itemize}
\item cannot be copied. Copying generates a pointer to the same object.
\item cannot be saved. Only the pointer to the external object will be stored.
The external object is destroyed by \code{R}'s garbage collector when \code{R}
closes, or when the \code{sparseConstraints} object is deleted or overwritten.
\end{itemize}
In a future version we might add a export option so that such objects can
be saved as a fixed-width file, for example.

Next, we define a new vector that matches these constraints and adjust it.
<<>>=
x_sparse <- c(330, 700, 1000, 30, 500, 200) 
(adjust(e, x_sparse))
@
Which gives the results as expected.


\section{About the adjustment algorithm and convergence}
\label{sect:algorithm}
The \code{rspa} package implements the {\em successive projection algorithm} of
\cite{pannekoek:2012}. Given a vector $\bs{x}^0$ for which $\bs{Ax}^0\not\leq \bs{b}$.
The algorithm solves the following minimization problem
\begin{eqnarray}
\lefteqn{
\argmin_{\bs{x}} (\bs{x}-\bs{x}^0)'\bs{W}(\bs{x} - \bs{x}^0)}\nonumber\\
s.t. &\: &\nonumber\\
\bs{Ax} &\leq& \bs{b},
\end{eqnarray}
where $\bs{W}$ is a diagonal weight matrix with all weights positive. By
default, all weights are chosen equal to $1$ in the package. In words, the
algorithm finds the vector with the smallest (weighted) Euclidean distance from
the starting vector $\bs{x}^0$ that obeys the restrictions.

To define the convergence criterion, we separate the equality from inequality
restrictions and write
\begin{eqnarray}
\label{eq:equalities}
\bs{A}_=\bs{x} &=& \bs{b}_=\\
\label{eq:inequalities}
\bs{A}_\leq\bs{x} &\leq& \bs{b}_\leq.
\end{eqnarray}
We now define $\varepsilon_=$ as the maximum difference between the 
left- and right hand side of \eqref{eq:equalities} (the infinity norm, also
know as $L_\infty$ or the Chebyshev distance):
\begin{equation}
\varepsilon_= = \left\|\bs{A}_=\bs{x} - \bs{b}_=\right\|_\infty.\\
\end{equation}
We also introduce the notation 
$
\bs{d}_\leq = \bs{A}_\leq\bs{x} - \bs{b}_\leq
$
and define
\begin{equation}
\varepsilon_\leq = \left\|\tfrac{1}{2}\left(|\bs{d}_\leq| +\bs{d}_\leq\right)\right\|_\infty.
\end{equation}
This formulation ensures that $\varepsilon_\leq >0$ only when at least one inequality
is not obeyed by $\bs{x}$. The algorithm works by iteratively improving $\bs{x}^{0}$
until the convergence parameter $\max(\varepsilon_=,\varepsilon_\leq)<\varepsilon$.
In other words: the algorithm terminates when the largest deviation from any of the 
(in)equality restrictions is met within a small parameter $\varepsilon$.



\section{Some notes on implementation}
\label{sect:implementation}
The algorithm of \cite{pannekoek:2012} has been implemented twice in this package.
Both implementations run as compiled \code{C} code which is linked to \code{R}.
The first implementation uses a dense matrix representation, and is called by
\code{adjust.matrix}. It is also the default method that is called by \code{adjust.editmatrix}.
However, if the optional argument \code{method='sparse'} is passed to \code{adjust.editmatrix},
the \code{editmatrix} object will be coerced to a \code{sparseConstraints} object prior to
adjusting.

The \code{sparseConstraints} object is represented under the hood as a \code{C}
\code{struct} that resides outside of \code{R}'s memory. It is an
\code{R\_ExternalPtr} object, packed in an environment which is put in a
\code{S3} class. Since the object is not in R's memory, there is no point in
trying to save a \code{sparseConstraints} object: only the pointer value will
be stored while the external structure will be destroyed when \code{R} closes.


\section{Conclusion}
With the \code{R} extension package \code{rspa}, we have made the successive
projection algorithm available for \code{R} users. In this paper we demonstrated
how (lots of) small adjustments problems can conveniently be solved using a
\code{editmatrix} definition of rules while large problems can be solved using
a sparse representation of the problem.

Future work may include extending the package to allow for the weight matrix
$\bs{W}$ to be non-diagonal and the possibility to read large problems from
multiple formats.


\section{Acknowledgements}
I am greatly indebted by Guido van den Heuvel who critically reviewed the
\code{C} code and pointed out many of the finer details of the \code{C89} and
\code{C99} standards to me. Any remaining bugs are of course mine. 


\bibliographystyle{chicago}
\DeclareRobustCommand{\VAN}[3]{#3}
\bibliography{rspa}

\end{document}



